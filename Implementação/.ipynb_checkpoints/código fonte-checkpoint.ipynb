{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from tensorflow.python.keras.applications.resnet import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixadas considerando as 7 classes da base de dados papsmear\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "# Fixada para imagens de três canais RGB\n",
    "CHANNELS = 3\n",
    "\n",
    "IMAGE_RESIZE = 200\n",
    "\n",
    "RESNET50_POOLING_AVERAGE = 'avg'\n",
    "DENSE_LAYER_ACTIVATION = 'softmax'\n",
    "\n",
    "OBJECTIVE_FUNCTION = 'categorical_crossentropy'\n",
    "\n",
    "# Métrica de precisão comum para todas as saídas, mas pode usar métricas diferentes para saídas diferentes\n",
    "LOSS_METRICS = ['accuracy']\n",
    "\n",
    "# EARLY_STOP_PATIENCE deve ser < NUM_EPOCHS\n",
    "NUM_EPOCHS = 10\n",
    "EARLY_STOP_PATIENCE = 10\n",
    "\n",
    "# O valor dessas etapas deve ser FACTOR adequado de nº de imagens em pastas de treinamento e teste, respectivamente\n",
    "# As imagens de treinamento processadas em cada etapa seriam no.-of-train-images / STEPS_PER_EPOCH_TRAINING\n",
    "STEPS_PER_EPOCH_TRAINING   = 8\n",
    "STEPS_PER_EPOCH_VALIDATION = 2\n",
    "\n",
    "# O valor dessas etapas deve ser FACTOR adequado de nº de imagens em pastas de treinamento e teste, respectivamente\n",
    "# NOTE que estes BATCH * são para lotes de Keras ImageDataGenerator para preencher a entrada de etapa de época\n",
    "BATCH_SIZE_TRAINING = 100\n",
    "BATCH_SIZE_VALIDATION = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_weights_path = 'imagenet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFER LEARNING\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Definindo a 1ª camada (Utilizando a aplicação ResNet50)\n",
    "model.add(ResNet50(include_top = False, pooling = RESNET50_POOLING_AVERAGE, weights = resnet_weights_path))\n",
    "\n",
    "# Definindo a 2ª camada como Densa para classificação de 7 classes usando a ativação do SoftMax\n",
    "model.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\n",
    "\n",
    "# Diga para não treinar o modelo de primeira camada (ResNet), pois ela já está treinado, isso considerando o \n",
    "# conceito de FROZEN no modelo base, ou seja, na primeira camada, esse é o conceito base\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilando o modelo de transferência de aprendizagem (Otimizador SGD)\n",
    "sgd = optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "model.compile(optimizer = sgd, loss = OBJECTIVE_FUNCTION, metrics = LOSS_METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation \n",
    "# Observação: O ideal é utilizar o conceito de data augmentation apenas no conjunto de imagens de treino, entretanto \n",
    "    # para fins de teste foi utilizado nos dois conjuntos de imagens (treino e teste)\n",
    "\n",
    "image_size = IMAGE_RESIZE\n",
    "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "        'images/treino',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=BATCH_SIZE_TRAINING,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "        'images/validacao',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=BATCH_SIZE_VALIDATION,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número máximo de etapas que esses geradores terão oportunidade de processar seu conteúdo de origem\n",
    "# len (train_generator) deve ser 'nº de imagens de trem disponíveis / BATCH_SIZE_TRAINING '\n",
    "# len (valid_generator) deve ser 'nº de imagens de trem disponíveis / BATCH_SIZE_VALIDATION '\n",
    "\n",
    "(BATCH_SIZE_TRAINING, len(train_generator), BATCH_SIZE_VALIDATION, len(validation_generator))\n",
    "#(BATCH_SIZE_TRAINING, len(train_generator), BATCH_SIZE_VALIDATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping => Pare o treinamento quando uma métrica monitorada parar de melhorar.\n",
    "# Assumindo que o objetivo de um treinamento é minimizar a perda. Com isso, a métrica a ser monitorada seria 'loss',\n",
    "#   e o modo seria 'min'. Um model.fit()loop de treinamento verificará ao final de cada época se a perda não está mais \n",
    "#   diminuindo, considerando o min_deltae patiencese aplicável. Uma vez que não esteja mais diminuindo, model.stop_trainingé\n",
    "#   marcado como Verdadeiro e o treinamento termina.\n",
    "\n",
    "cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE)\n",
    "\n",
    "# ModelCheckpoint => Retorno de chamada para salvar o modelo Keras ou pesos do modelo com alguma frequência.\n",
    "# ModelCheckpointO retorno de chamada é usado em conjunto com o treinamento model.fit()\n",
    "#  para salvar um modelo ou pesos (em um arquivo de ponto de verificação) em algum intervalo, \n",
    "#  para que o modelo ou pesos possam ser carregados posteriormente para continuar o treinamento do estado salvo.\n",
    "\n",
    "cb_checkpointer = ModelCheckpoint(filepath = 'images/rede.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH_TRAINING,\n",
    "    epochs = NUM_EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=STEPS_PER_EPOCH_VALIDATION,\n",
    "    callbacks=[cb_checkpointer, cb_early_stopper]\n",
    ")\n",
    "\n",
    "# LOAD_WEIGHTS => O savefile inclui:\n",
    "# A arquitetura do modelo, permitindo reinstanciar o modelo.\n",
    "# Os pesos do modelo.\n",
    "# O estado do otimizador, permitindo retomar o treinamento exatamente de onde você parou.\n",
    "# Isso permite que você salve todo o estado de um modelo em um único arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas de treinamento\n",
    "print(fit_history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize = (15,8)) \n",
    "    \n",
    "plt.subplot(221)  \n",
    "plt.plot(fit_history.history['accuracy'])  \n",
    "plt.plot(fit_history.history['val_accuracy'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'valid'])\n",
    "    \n",
    "plt.subplot(222)  \n",
    "plt.plot(fit_history.history['loss'])  \n",
    "plt.plot(fit_history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
